{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this lab we're going to do a style-based classification of authors, based on sample of books. This is the same case-study we did in the lab 3.3. But last time we used an SVM classifier (support vector machine) using *scikit-learn*. So this time we're going to solve the same problem using an MLP classifier (multi-layer perceptron) using *tensorflow*.\n",
                "\n",
                "As before, this lab shows the simpler version. If you want to dig more into the details, have a look at the examples in the *text_analytics()* package."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from text_analytics import text_analytics\n",
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "ai = text_analytics()\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's load the books that we need for each author."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"Gutenberg.1850.Authors.gz\"\n",
                "file = os.path.join(ai.data_dir, file)\n",
                "df = pd.read_csv(file, index_col = 0)\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And now our data is loaded. Let's look at the survey of authors again."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "freqs = ai.print_labels(df, \"Author\")\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So now we have (1) our data from Project Gutenberg and (2) our style vectorizer (function word n-grams). We're going to classify these books by author. The basic code is below; this just called our *text_analytics* package. That package splits the data into training and testing data, learns a classifier, and then evaluates the classifier. We're telling the package to use \"Author\" as the ground-truth class, with style features.\n",
                "\n",
                "How many samples do we have in total?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(len(df))\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What's different here is the, last time, we used an SVM and this time we're going to use an MLP. The SVM trains all at once. But an MLP trains over time, so we'll see the model's progress as it learns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai.mlp(df, labels = \"Author\", features = \"style\")\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Be patient**\n",
                "\n",
                "And there we go! We're looking at the classifier accuracy. \n",
                "\n",
                "This will change a bit from the lecture, because we're using random train\/test splits. That means the classifier is looking at different data each time. If you want more advanced examples for how to solve this city classification problem, take a look at the *text_analytics.mlp()* function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}