{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this lab, we'll expand on our wordclouds by using *groupby* to make a new wordcloud every year. And we'll also use TF-IDF weghting to give us a better sense of what's changing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from text_analytics import text_analytics\n",
                "from text_analytics import load\n",
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "ai = text_analytics()\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This dataset contains speeches in the US Congress from  1931 to 1969. It will take a bit to load!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"US.Congress.1931-1969.gz\"\n",
                "file = os.path.join(ai.data_dir, file)\n",
                "df = pd.read_csv(file)\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First, we'll iterate over the data by year, using our *groupby* function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "counts = []\n",
                "for year, year_df in df.groupby(\"Year\"):\n",
                "    counts.append([year, len(year_df)])\n",
                "\n",
                "counts = pd.DataFrame(counts, columns = [\"Year\", \"N\"])\n",
                "counts = counts.set_index(\"Year\", drop = True)\n",
                "print(counts)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And then we'll plot this to get an idea of the rate of speeches over time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.rcParams['figure.figsize'] = [20,12]\n",
                "plt.rcParams['figure.dpi'] = 120\n",
                "\n",
                "sns.barplot(x = counts.index, y = \"N\", data = counts)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, because it takes awhile to fit the TF-IDf model, let's load one that is pre-trained. We first load the pre-trained version, and then we tell the *ai* object to use that version. There are two parts here: the vectorizer and a phrase model that uses PMI to find sequences like \"New York.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai_state = load(\"tf-idf.US.Congress.1931-2016\")\n",
                "ai.tfidf_vectorizer = ai_state.tfidf_vectorizer\n",
                "ai.phrases = ai_state.phrases\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "year_df = df.loc[df[\"Year\"] == 1955]\n",
                "print(year_df)\n",
                "ai.wordclouds(year_df, stage = 4, features = \"tfidf\")\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This will take a moment to calculate. Then, we'll see a wordcloud for congress in 1955. If you want to see a different year, change the part of the line where it says *1955*!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}