{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this lab we're going to do a style-based classification of authors, based on printed books. This is the same case-study we saw in the lecture. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from text_analytics import text_analytics\n",
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "ai = text_analytics()\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's load the books that we need for each city. We're looking at authors born between 1850 and 1900, each of whom has a number of books here. That makes sure that we learn to *generalize* so that we're not just predicting individual books. Each sample is about 5k from a book."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"Gutenberg.1850.Authors.gz\"\n",
                "file = os.path.join(ai.data_dir, file)\n",
                "df = pd.read_csv(file, index_col = 0)\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We're going to use function word n-grams. These are pre-defined, so we don't need to fit a model before we use them. Let's take a look at how many authors we have here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "freq = ai.print_labels(df, \"Author\")\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is a lot of samples per author. So it is going to be difficult to make generalizations that tell us who wrote what using just function word n-grams like \"there was\" or \"in the\". So now we have (1) our data from Project Gutenberg and (2) our style vectorizer (function word n-grams). We're going to classify these by author. The basic code is below; this just called our *text_analytics* package. That package splits the data into training and testing data, learns a classifier, and then evaluates the classifier. We're telling the package to use \"Author\" as the ground-truth class, with stylistic features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai.svm(df, labels = \"Author\", features = \"style\")\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Be patient**\n",
                "\n",
                "And there we go! We're looking at the classifier accuracy. \n",
                "\n",
                "This will change a bit from the lecture, because we're using random train\/test splits. That means the classifier is looking at different data each time. If you want more advanced examples for how to solve this authorship classification problem, take a look at the *text_analytics.svm()* function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}