{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Welcome to our first lab for Module 3!\n",
                "\n",
                "Today we are going to look at text classification across 42 languages. Now that we've learned about *precision* and *recall* and *f-score*, we can use these metrics to look at how well our methods work for languages that aren't English!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from text_analytics import text_analytics\n",
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "ai = text_analytics()\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The task that we'll be looking at is simple but important: identifying the register or source that data comes from. So, we'll be learning how to determine whether a sample comes from Wikipedia, Twitter, or OpenSubtitles. This can be important in a pipeline; for example, we might want to have a different model for each type of data. \n",
                "\n",
                "Regardless, for our purposes this is going to let us compare results across all these languages. Let's load a csv file that contains the classification results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"register.csv\"\n",
                "file = os.path.join(ai.data_dir, file)\n",
                "df = pd.read_csv(file)\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This is a lot of information, too much to look at. So, let's narrow this down to the *f-score*. Since this is the harmonic mean of precision and recall, it makes sense to focus on just this one metric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.loc[:,[\"Language\", \"Register\", \"F-Score\"]]\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, this is still a bunch of information. The *Weighted_AVG* gives us an overview of how well the classifier works across all the registers. So let's just look at it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.loc[df[\"Register\"] == \"Weighted_AVG\"]\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And we can make the \"Language\" column the index now, as well. Because we have only one row per language."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df.set_index(\"Language\", drop = True)\n",
                "df = df.drop(columns = [\"Register\"])\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's make a chart!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.rcParams['figure.figsize'] = [20,12]\n",
                "plt.rcParams['figure.dpi'] = 120\n",
                "\n",
                "ax = sns.barplot(y = df.index, x = \"F-Score\", data = df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So the same basic methods work for a lot of languages. But some languages, like Japanese and Chinese, are going to require special processing. Because their writing systems are so different.\n",
                "\n",
                "You'll notice that \"Language\" here is a three-letter code. We're using the ISO-639(2) codes. That's because languages refer to themselves and to each other using a bunch of different terms. So, we need to use an international standard to be consistent. For reference, the codes we've just used are listed below with their informal English counterpart."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "| Code       | Language     | Code     | Language     |\n",
                "| :--------- | :----------: | -------: | -----------: |\n",
                "|  ara       | Arabic       | lav      | Latvian      |\n",
                "|  bul       | Bulgarian    | lit      | Lithuanian   | \n",
                "|  cat       | Catalan      | mkd      | Macedonian   | \n",
                "|  ces       | Czech        | nld      | Dutch        | \n",
                "|  dan       | Danish       | nor      | Norwegian    | \n",
                "|  deu       | German       | pol      | Polish       | \n",
                "|  ell       | Greek        | por      | Portuguese   | \n",
                "|  eng       | English      | ron      | Romanian     | \n",
                "|  est       | Estonian     | rus      | Russian      | \n",
                "|  fas       | Farsi        | slk      | Slovak       | \n",
                "|  fin       | Finnish      | slv      | Slovenian    | \n",
                "|  fra       | French       | spa      | Spanish      | \n",
                "|  hin       | Hindi        | sqi      | Albanian     | \n",
                "|  hun       | Hungarian    | swe      | Swedish      | \n",
                "|  ind       | Indonesian   | tam      | Tamil        | \n",
                "|  isl       | Icelandic    | tgl      | Tagalog      | \n",
                "|  ita       | Italian      | tur      | Turkish      | \n",
                "|  jpn       | Japanese     | ukr      | Ukrainian    | \n",
                "|  kat       | Georgian     | urd      | Urdu         | \n",
                "|  kaz       | Kazakh       | vie      | Vietnamese   | \n",
                "|  kor       | Korean       | zho      | Chinese      | "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's take a look at what these languages look like. We'll use \"ara\" for Arabic. But you can try other languages by replacing that with the correct code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "file = \"Register.ara.gz\"\n",
                "file = os.path.join(ai.data_dir, file)\n",
                "df = pd.read_csv(file, index_col = 0)\n",
                "print(df)\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, today we've looked a bit further at classification results. We've seen that most (but not all) have similar results on the same task. And we've had a chance to look at some non-English data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}